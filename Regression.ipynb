{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1- What is Simple Linear Regression?**\n",
        "\n",
        "**Ans--**Simple Linear Regression is a statistical method used to model the relationship between a single independent variable (X) and a dependent variable (Y) by fitting a straight line through the data points."
      ],
      "metadata": {
        "id": "BjTfj74QgCbJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.What are the key assumptions of Simple Linear Regression?**\n",
        "\n",
        "**Ans--** - Linearity: The relationship between X and Y is linear.\n",
        "      - Independence: Observations are independent of each other.\n",
        "      - Homoscedasticity: Constant variance of residuals.\n",
        "      - Normality: Residuals are normally distributed."
      ],
      "metadata": {
        "id": "5o0WSnt6grEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.What does the coefficient m represent in the equation Y=mX+c**\n",
        "\n",
        "**Ans--** The coefficient \\( m \\) represents the slope of the line, indicating the change in \\( Y \\) for a one-unit increase in \\( X \\)."
      ],
      "metadata": {
        "id": "WQVBn0Kdg9kB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.What does the intercept c represent in the equation Y=mX+c?**\n",
        "\n",
        "**Ans--**The intercept \\( c \\) represents the value of \\( Y \\) when \\( X \\) is zero.\n"
      ],
      "metadata": {
        "id": "2Pf-10G2hLzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.How do we calculate the slope m in Simple Linear Regression?**\n",
        "\n",
        "**Ans--**The slope \\( m \\) is calculated as:\n",
        "   \\[\n",
        "   m = \\frac{\\text{Cov}(X, Y)}{\\text{Var}(X)}\n",
        "   \\]"
      ],
      "metadata": {
        "id": "mN52lUIYhuUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.**What is the purpose of the least squares method in Simple Linear Regression?**\n",
        "\n",
        "**Ans--**The least squares method minimizes the sum of the squared differences between the observed values and the predicted values."
      ],
      "metadata": {
        "id": "Wtf-UlIDh5qp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.How is the coefficient of determination (R²) interpreted in Simple Linear Regression?**\n",
        "\n",
        "**Ans--**  \\( R^2 \\) indicates the proportion of the variance in the dependent variable \\( Y \\) that is explained by the independent variable \\( X \\).\n"
      ],
      "metadata": {
        "id": "XpJTjQJ0iTm5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.- What is Multiple Linear Regression?**\n",
        "\n",
        "**Ans--**Multiple Linear Regression models the relationship between a dependent variable and multiple independent variables.\n"
      ],
      "metadata": {
        "id": "dGROuCqNiibB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.What is the main difference between Simple and Multiple Linear Regression?**\n",
        "\n",
        "**Ans--**  Simple Linear Regression involves one independent variable, while Multiple Linear Regression involves two or more independent variables."
      ],
      "metadata": {
        "id": "VbPHILURisc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.What are the key assumptions of Multiple Linear Regression?**\n",
        "\n",
        "**Ans--** - Linearity.\n",
        "          - Independence of errors.\n",
        "          - Homoscedasticity.\n",
        "          - Multivariate normality.\n",
        "          - No multicollinearity.\n"
      ],
      "metadata": {
        "id": "Uh21WgeCi8ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?**\n",
        "\n",
        "**Ans--**Heteroscedasticity occurs when the variance of residuals is not constant, leading to inefficient estimates and unreliable hypothesis tests."
      ],
      "metadata": {
        "id": "pV2hIgOojiEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12.- How can you improve a Multiple Linear Regression model with high multicollinearity?**\n",
        "\n",
        "**Ans--** - Remove highly correlated predictors.\n",
        "          - Use techniques like Ridge or Lasso Regression.\n",
        "          - Use Principal Component Analysis (PCA).\n"
      ],
      "metadata": {
        "id": "R4a9PgiAjuLB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13.What are some common techniques for transforming categorical variables for use in regression models?**\n",
        "\n",
        "**Ans--** - One-hot encoding.\n",
        "          - Label encoding.\n",
        "          - Binary encoding."
      ],
      "metadata": {
        "id": "mOFyz1T5kAFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14.What is the role of interaction terms in Multiple Linear Regression?**\n",
        "\n",
        "**Ans-** Interaction terms capture the combined effect of two or more variables on the dependent variable."
      ],
      "metadata": {
        "id": "OhGbG7gukQwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15.- How can the interpretation of intercept differ between Simple and Multiple Linear Regression?**\n",
        "\n",
        "**Ans.** In Simple Linear Regression, the intercept represents the value of \\( Y \\) when \\( X \\) is zero. In Multiple Linear Regression, it represents \\( Y \\) when all predictors are zero.\n"
      ],
      "metadata": {
        "id": "IGxcnEd-kbKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16.What is the significance of the slope in regression analysis, and how does it affect predictions?**\n",
        "\n",
        "**Ans-**The slope quantifies the relationship between an independent variable and the dependent variable, indicating how much \\( Y \\) changes for a unit change in \\( X \\).\n"
      ],
      "metadata": {
        "id": "_lJDc13Nkm-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17.How does the intercept in a regression model provide context for the relationship between variables?**\n",
        "\n",
        "**Ans-**The intercept provides a baseline value of the dependent variable when all predictors are zero."
      ],
      "metadata": {
        "id": "kEpW1kbuk3nh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18.What are the limitations of using R² as a sole measure of model performance?**\n",
        "\n",
        "**Ans-**- It does not account for model complexity.\n",
        "        - It may give a high value even for overfitted models.\n",
        "        - Adjusted \\( R^2 \\) is a better alternative for multiple predictors.\n"
      ],
      "metadata": {
        "id": "F-A-_pBElF8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19.**How would you interpret a large standard error for a regression coefficient?**\n",
        "\n",
        "**Ans--**  A large standard error indicates that the coefficient estimate is less precise, leading to wider confidence intervals.\n"
      ],
      "metadata": {
        "id": "FZ4kZdy_lZOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20.How can heteroscedasticity be identified in residual plots, and why is it important to address it?**\n",
        "\n",
        "**Ans-**Heteroscedasticity is identified when residuals display a funnel-shaped pattern in plots. Addressing it ensures more reliable hypothesis tests and confidence intervals.\n"
      ],
      "metadata": {
        "id": "1m6cYQJVlsAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21.** What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?**\n",
        "\n",
        "**Ans-**caling ensures that predictors are on the same scale, which is essential for interpreting coefficients and improving numerical stability.\n"
      ],
      "metadata": {
        "id": "mMdZWtEul6U6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22.Why is it important to scale variables in Multiple Linear Regression?**\n",
        "\n",
        "**Ans-**Scaling ensures that predictors are on the same scale, which is essential for interpreting coefficients and improving numerical stability.\n",
        "\n"
      ],
      "metadata": {
        "id": "P2-VlIShmLu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**23.- What is polynomial regression?**\n",
        "\n",
        "**Ans-**Polynomial regression models the relationship between the dependent variable and independent variable(s) as an nth-degree polynomial."
      ],
      "metadata": {
        "id": "qg2408SUmbKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**24.How does polynomial regression differ from linear regression**\n",
        "\n",
        "**Ans-** While linear regression models a straight-line relationship, polynomial regression fits a curve to capture non-linear relationships.\n"
      ],
      "metadata": {
        "id": "mz8H-AgOmoxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**25.When is polynomial regression used?**\n",
        "**Ans-**When the relationship between variables is non-linear.\n"
      ],
      "metadata": {
        "id": "-zUH4lf5nCc6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**26.What is the general equation for polynomial regression?**\n",
        "\n",
        "**Ans-**\\[\n",
        "    Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\dots + \\beta_nX^n\n",
        "    \\]"
      ],
      "metadata": {
        "id": "quAtihp0nQwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**27.Can polynomial regression be applied to multiple variables?**\n",
        "\n",
        "**Ans-**    Yes, polynomial terms can be added for multiple variables and their interactions.\n",
        "\n"
      ],
      "metadata": {
        "id": "NTLPNzyXndzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**28.What are the limitations of polynomial regression?**\n",
        "\n",
        "**Ans-**- Prone to overfitting for high-degree polynomials.\n",
        "        - Sensitive to outliers.\n",
        "        - May lack interpretability.\n"
      ],
      "metadata": {
        "id": "X4r7Cfjwno7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**29.What methods can be used to evaluate model fit when selecting the degree of a polynomial?**\n",
        "\n",
        "**Ans-**- Cross-validation.\n",
        "        - Adjusted \\( R^2 \\).\n",
        "        - Mean Squared Error (MSE)"
      ],
      "metadata": {
        "id": "Ev1u3Vain2eR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**30.Why is visualization important in polynomial regression**\n",
        "\n",
        "**Ans-**Visualization helps assess how well the model fits the data and identify potential overfitting or underfitting."
      ],
      "metadata": {
        "id": "Oe1KVFmjoN3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**31.How is polynomial regression implemented in Python?**\n",
        "\n",
        "**Ans-** Using libraries like NumPy, Scikit-learn, or Statsmodels with steps such as:\n",
        "    - Generating polynomial features with PolynomialFeatures.\n",
        "    - Fitting the model using LinearRegression."
      ],
      "metadata": {
        "id": "aMh_xEoEoZYJ"
      }
    }
  ]
}